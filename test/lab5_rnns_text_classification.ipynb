{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:48:49.977014Z",
     "start_time": "2025-11-11T12:48:49.539322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Setup & Data loading\n",
    "# =========================\n",
    "import os, random, math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "93f266bacff8c8ab",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:48:51.249318Z",
     "start_time": "2025-11-11T12:48:51.218906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "# 1) Load data (2 cột: text, category).\n",
    "df_train = pd.read_csv('../data/hwu/train.csv', header=None, names=['text', 'category'])\n",
    "df_val   = pd.read_csv('../data/hwu/val.csv', header=None, names=['text', 'category'])\n",
    "df_test  = pd.read_csv('../data/hwu/test.csv', header=None, names=['text', 'category'])\n",
    "\n",
    "# Nếu dòng đầu là header cũ bị đọc nhầm (ví dụ cell đầu tiên là 'text' hoặc 'category'), ta bỏ:\n",
    "def drop_misread_header(df):\n",
    "    if isinstance(df.iloc[0,0], str) and df.iloc[0,0].strip().lower() in {\"text\",\"utterance\",\"sentence\"}:\n",
    "        return df.iloc[1:].reset_index(drop=True)\n",
    "    if isinstance(df.iloc[0,1], str) and df.iloc[0,1].strip().lower() in {\"category\",\"intent\",\"label\"}:\n",
    "        return df.iloc[1:].reset_index(drop=True)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "df_train = drop_misread_header(df_train)\n",
    "df_val   = drop_misread_header(df_val)\n",
    "df_test  = drop_misread_header(df_test)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Validation shape:\", df_val.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "print(df_train.head())"
   ],
   "id": "b8d0648f03d9d067",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (8954, 2)\n",
      "Validation shape: (1076, 2)\n",
      "Test shape: (1076, 2)\n",
      "                                                text     category\n",
      "0                what alarms do i have set right now  alarm_query\n",
      "1                    checkout today alarm of meeting  alarm_query\n",
      "2                              report alarm settings  alarm_query\n",
      "3  see see for me the alarms that you have set to...  alarm_query\n",
      "4                       is there an alarm for ten am  alarm_query\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:48:54.532737Z",
     "start_time": "2025-11-11T12:48:54.122880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean NaN (nếu có)\n",
    "for d in (df_train, df_val, df_test):\n",
    "    d[\"text\"] = d[\"text\"].astype(str).fillna(\"\")\n",
    "    d[\"category\"] = d[\"category\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.concat([df_train[\"category\"], df_val[\"category\"], df_test[\"category\"]], axis=0))\n",
    "y_train = le.transform(df_train[\"category\"])\n",
    "y_val   = le.transform(df_val[\"category\"])\n",
    "y_test  = le.transform(df_test[\"category\"])\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Num classes:\", num_classes)"
   ],
   "id": "764a544b8a89a3b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:48:58.133503Z",
     "start_time": "2025-11-11T12:48:56.072854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utility: macro F1 + report\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# ==========================================================\n",
    "# Nhiệm vụ 1: TF-IDF + Logistic Regression (Baseline)\n",
    "# ==========================================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000, ngram_range=(1,2)),\n",
    "    LogisticRegression(max_iter=1000, n_jobs=None)  # n_jobs=None để tương thích nhiều môi trường\n",
    ")\n",
    "tfidf_lr_pipeline.fit(df_train[\"text\"], y_train)\n",
    "\n",
    "y_pred_lr = tfidf_lr_pipeline.predict(df_test[\"text\"])\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average=\"macro\")\n",
    "\n",
    "print(\"\\n[TF-IDF + LR] Classification report (test):\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=le.classes_))\n",
    "\n",
    "# LR không dùng Keras, không có test loss theo nghĩa cross-entropy ở Keras\n",
    "loss_lr = np.nan"
   ],
   "id": "b551b27a2574df97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF + LR] Classification report (test):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alarm_query       0.95      0.95      0.95        19\n",
      "            alarm_remove       1.00      0.73      0.84        11\n",
      "               alarm_set       0.85      0.89      0.87        19\n",
      "       audio_volume_down       1.00      0.75      0.86         8\n",
      "       audio_volume_mute       0.92      0.80      0.86        15\n",
      "         audio_volume_up       1.00      1.00      1.00        13\n",
      "          calendar_query       0.52      0.58      0.55        19\n",
      "         calendar_remove       0.78      0.95      0.86        19\n",
      "            calendar_set       0.87      0.68      0.76        19\n",
      "          cooking_recipe       0.93      0.68      0.79        19\n",
      "        datetime_convert       0.78      0.88      0.82         8\n",
      "          datetime_query       0.71      0.89      0.79        19\n",
      "        email_addcontact       0.88      0.88      0.88         8\n",
      "             email_query       0.83      0.79      0.81        19\n",
      "      email_querycontact       0.93      0.68      0.79        19\n",
      "         email_sendemail       0.77      0.89      0.83        19\n",
      "          general_affirm       0.95      1.00      0.97        19\n",
      "     general_commandstop       1.00      1.00      1.00        19\n",
      "         general_confirm       1.00      1.00      1.00        19\n",
      "        general_dontcare       0.90      1.00      0.95        19\n",
      "         general_explain       1.00      1.00      1.00        19\n",
      "            general_joke       1.00      1.00      1.00        12\n",
      "          general_negate       1.00      0.95      0.97        19\n",
      "          general_praise       0.95      1.00      0.97        19\n",
      "          general_quirky       0.33      0.26      0.29        19\n",
      "          general_repeat       0.95      1.00      0.97        19\n",
      "            iot_cleaning       1.00      1.00      1.00        16\n",
      "              iot_coffee       0.90      0.95      0.92        19\n",
      "     iot_hue_lightchange       0.79      0.79      0.79        19\n",
      "        iot_hue_lightdim       0.91      0.83      0.87        12\n",
      "        iot_hue_lightoff       0.86      0.95      0.90        19\n",
      "         iot_hue_lighton       0.40      0.67      0.50         3\n",
      "         iot_hue_lightup       0.93      0.93      0.93        14\n",
      "            iot_wemo_off       0.80      0.89      0.84         9\n",
      "             iot_wemo_on       0.62      0.71      0.67         7\n",
      "       lists_createoradd       0.65      0.79      0.71        19\n",
      "             lists_query       0.83      0.79      0.81        19\n",
      "            lists_remove       0.86      0.95      0.90        19\n",
      "          music_likeness       0.57      0.67      0.62        18\n",
      "             music_query       0.65      0.58      0.61        19\n",
      "          music_settings       1.00      0.43      0.60         7\n",
      "              news_query       0.80      0.63      0.71        19\n",
      "          play_audiobook       0.90      0.95      0.92        19\n",
      "               play_game       0.92      0.58      0.71        19\n",
      "              play_music       0.52      0.68      0.59        19\n",
      "           play_podcasts       1.00      0.84      0.91        19\n",
      "              play_radio       0.93      0.74      0.82        19\n",
      "             qa_currency       0.89      0.89      0.89        19\n",
      "           qa_definition       0.95      0.95      0.95        19\n",
      "              qa_factoid       0.38      0.53      0.44        19\n",
      "                qa_maths       0.93      0.93      0.93        14\n",
      "                qa_stock       0.95      0.95      0.95        19\n",
      "   recommendation_events       0.79      0.79      0.79        19\n",
      "recommendation_locations       0.80      0.84      0.82        19\n",
      "   recommendation_movies       0.91      1.00      0.95        10\n",
      "             social_post       0.95      0.95      0.95        19\n",
      "            social_query       0.79      0.83      0.81        18\n",
      "          takeaway_order       0.76      0.68      0.72        19\n",
      "          takeaway_query       0.89      0.89      0.89        19\n",
      "         transport_query       0.70      0.84      0.76        19\n",
      "          transport_taxi       1.00      1.00      1.00        18\n",
      "        transport_ticket       0.94      0.79      0.86        19\n",
      "       transport_traffic       0.95      0.95      0.95        19\n",
      "           weather_query       0.68      0.68      0.68        19\n",
      "\n",
      "                accuracy                           0.83      1076\n",
      "               macro avg       0.84      0.83      0.83      1076\n",
      "            weighted avg       0.84      0.83      0.83      1076\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:49:17.143441Z",
     "start_time": "2025-11-11T12:49:05.983644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Nhiệm vụ 2: Word2Vec (trung bình) + Dense (Keras)\n",
    "# ==========================================================\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# 1) Train Word2Vec trên text train (có thể thêm val để phong phú)\n",
    "sentences_train = [simple_preprocess(t) for t in df_train[\"text\"].tolist()]\n",
    "sentences_all   = sentences_train  # hoặc: sentences_train + [simple_preprocess(t) for t in df_val[\"text\"]]\n",
    "w2v_model = Word2Vec(sentences=sentences_all, vector_size=100, window=5, min_count=1, workers=4, seed=SEED)\n",
    "\n",
    "# 2) Hàm chuyển câu -> vector trung bình\n",
    "def sentence_to_avg_vector(text, model, vector_size=100):\n",
    "    tokens = simple_preprocess(text)\n",
    "    vectors = []\n",
    "    for tok in tokens:\n",
    "        if tok in model.wv:\n",
    "            vectors.append(model.wv[tok])\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(vector_size, dtype=np.float32)\n",
    "    return np.mean(vectors, axis=0).astype(np.float32)\n",
    "\n",
    "# 3) Tạo X_avg cho train/val/test\n",
    "X_train_avg = np.vstack([sentence_to_avg_vector(t, w2v_model, w2v_model.vector_size) for t in df_train[\"text\"]])\n",
    "X_val_avg   = np.vstack([sentence_to_avg_vector(t, w2v_model, w2v_model.vector_size) for t in df_val[\"text\"]])\n",
    "X_test_avg  = np.vstack([sentence_to_avg_vector(t, w2v_model, w2v_model.vector_size) for t in df_test[\"text\"]])\n",
    "\n",
    "# 4) Mô hình Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_oh = to_categorical(y_train, num_classes)\n",
    "y_val_oh   = to_categorical(y_val,   num_classes)\n",
    "y_test_oh  = to_categorical(y_test,  num_classes)\n",
    "\n",
    "dense_avg = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "dense_avg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "hist_dense = dense_avg.fit(\n",
    "    X_train_avg, y_train_oh,\n",
    "    validation_data=(X_val_avg, y_val_oh),\n",
    "    epochs=30, batch_size=64, callbacks=[es], verbose=0\n",
    ")\n",
    "\n",
    "test_loss_dense, test_acc_dense = dense_avg.evaluate(X_test_avg, y_test_oh, verbose=0)\n",
    "y_pred_dense = dense_avg.predict(X_test_avg, verbose=0).argmax(axis=1)\n",
    "f1_dense = f1_score(y_test, y_pred_dense, average=\"macro\")\n",
    "\n",
    "print(\"\\n[W2V Avg + Dense] Test loss:\", test_loss_dense, \" | Test macro-F1:\", f1_dense)\n",
    "print(classification_report(y_test, y_pred_dense, target_names=le.classes_))"
   ],
   "id": "2001028ccdae3963",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 19:49:07.176706: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-11 19:49:07.616668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 19:49:09.042764: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-11-11 19:49:09.583198: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[W2V Avg + Dense] Test loss: 3.0917906761169434  | Test macro-F1: 0.14842877911622787\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alarm_query       0.16      0.32      0.21        19\n",
      "            alarm_remove       0.67      0.18      0.29        11\n",
      "               alarm_set       0.47      0.84      0.60        19\n",
      "       audio_volume_down       0.25      0.12      0.17         8\n",
      "       audio_volume_mute       0.17      0.07      0.10        15\n",
      "         audio_volume_up       0.18      0.15      0.17        13\n",
      "          calendar_query       0.09      0.05      0.07        19\n",
      "         calendar_remove       0.00      0.00      0.00        19\n",
      "            calendar_set       0.11      0.05      0.07        19\n",
      "          cooking_recipe       0.25      0.05      0.09        19\n",
      "        datetime_convert       0.00      0.00      0.00         8\n",
      "          datetime_query       0.13      0.63      0.21        19\n",
      "        email_addcontact       0.00      0.00      0.00         8\n",
      "             email_query       0.09      0.16      0.12        19\n",
      "      email_querycontact       0.00      0.00      0.00        19\n",
      "         email_sendemail       0.27      0.37      0.31        19\n",
      "          general_affirm       0.25      0.21      0.23        19\n",
      "     general_commandstop       0.29      0.21      0.24        19\n",
      "         general_confirm       0.47      0.74      0.57        19\n",
      "        general_dontcare       0.20      0.47      0.28        19\n",
      "         general_explain       0.17      0.26      0.20        19\n",
      "            general_joke       0.00      0.00      0.00        12\n",
      "          general_negate       0.21      0.32      0.25        19\n",
      "          general_praise       0.39      0.63      0.48        19\n",
      "          general_quirky       0.00      0.00      0.00        19\n",
      "          general_repeat       0.39      0.37      0.38        19\n",
      "            iot_cleaning       0.60      0.38      0.46        16\n",
      "              iot_coffee       0.46      0.32      0.38        19\n",
      "     iot_hue_lightchange       0.33      0.58      0.42        19\n",
      "        iot_hue_lightdim       0.22      0.17      0.19        12\n",
      "        iot_hue_lightoff       0.34      0.84      0.48        19\n",
      "         iot_hue_lighton       0.00      0.00      0.00         3\n",
      "         iot_hue_lightup       0.25      0.07      0.11        14\n",
      "            iot_wemo_off       0.50      0.11      0.18         9\n",
      "             iot_wemo_on       0.00      0.00      0.00         7\n",
      "       lists_createoradd       0.27      0.68      0.39        19\n",
      "             lists_query       0.05      0.21      0.08        19\n",
      "            lists_remove       0.13      0.21      0.16        19\n",
      "          music_likeness       0.00      0.00      0.00        18\n",
      "             music_query       0.00      0.00      0.00        19\n",
      "          music_settings       0.00      0.00      0.00         7\n",
      "              news_query       0.06      0.05      0.06        19\n",
      "          play_audiobook       0.10      0.11      0.10        19\n",
      "               play_game       0.00      0.00      0.00        19\n",
      "              play_music       0.07      0.05      0.06        19\n",
      "           play_podcasts       0.00      0.00      0.00        19\n",
      "              play_radio       0.12      0.05      0.07        19\n",
      "             qa_currency       0.00      0.00      0.00        19\n",
      "           qa_definition       0.25      0.11      0.15        19\n",
      "              qa_factoid       0.15      0.32      0.20        19\n",
      "                qa_maths       0.00      0.00      0.00        14\n",
      "                qa_stock       0.00      0.00      0.00        19\n",
      "   recommendation_events       0.17      0.47      0.25        19\n",
      "recommendation_locations       0.00      0.00      0.00        19\n",
      "   recommendation_movies       0.00      0.00      0.00        10\n",
      "             social_post       0.14      0.21      0.17        19\n",
      "            social_query       0.00      0.00      0.00        18\n",
      "          takeaway_order       0.33      0.11      0.16        19\n",
      "          takeaway_query       0.00      0.00      0.00        19\n",
      "         transport_query       0.06      0.05      0.06        19\n",
      "          transport_taxi       0.00      0.00      0.00        18\n",
      "        transport_ticket       0.26      0.53      0.34        19\n",
      "       transport_traffic       0.00      0.00      0.00        19\n",
      "           weather_query       0.00      0.00      0.00        19\n",
      "\n",
      "                accuracy                           0.20      1076\n",
      "               macro avg       0.16      0.18      0.15      1076\n",
      "            weighted avg       0.16      0.20      0.16      1076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:50:21.002448Z",
     "start_time": "2025-11-11T12:49:44.090364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Nhiệm vụ 3: Embedding Pre-trained + LSTM (đóng băng)\n",
    "# ==========================================================\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "\n",
    "# 1) Tokenizer + sequences + padding\n",
    "def estimate_max_len(texts, q=0.95):\n",
    "    lens = [len(simple_preprocess(t)) for t in texts]\n",
    "    return max(5, int(np.quantile(lens, q)))\n",
    "\n",
    "max_len = estimate_max_len(df_train[\"text\"])\n",
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(df_train[\"text\"].tolist())\n",
    "\n",
    "def to_padded(texts, tokenizer, max_len):\n",
    "    seqs = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(seqs, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "X_train_pad = to_padded(df_train[\"text\"], tokenizer, max_len)\n",
    "X_val_pad   = to_padded(df_val[\"text\"], tokenizer, max_len)\n",
    "X_test_pad  = to_padded(df_test[\"text\"], tokenizer, max_len)\n",
    "\n",
    "vocab_size   = len(tokenizer.word_index) + 1\n",
    "embedding_dim = w2v_model.vector_size\n",
    "\n",
    "# 2) Embedding matrix từ Word2Vec\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim), dtype=np.float32)\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "# 3) LSTM với embedding pretrained (đóng băng)\n",
    "from tensorflow.keras.layers import Dense as KDense, Dropout as KDropout\n",
    "from tensorflow.keras.models import Sequential as KSequential\n",
    "\n",
    "lstm_pre = KSequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_len,\n",
    "        trainable=False\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    KDense(num_classes, activation='softmax')\n",
    "])\n",
    "lstm_pre.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es2 = EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "hist_pre = lstm_pre.fit(\n",
    "    X_train_pad, y_train_oh,\n",
    "    validation_data=(X_val_pad, y_val_oh),\n",
    "    epochs=20, batch_size=64, callbacks=[es2], verbose=0\n",
    ")\n",
    "\n",
    "test_loss_pre, test_acc_pre = lstm_pre.evaluate(X_test_pad, y_test_oh, verbose=0)\n",
    "y_pred_pre = lstm_pre.predict(X_test_pad, verbose=0).argmax(axis=1)\n",
    "f1_pre = f1_score(y_test, y_pred_pre, average=\"macro\")\n",
    "print(\"\\n[LSTM + Pretrained Emb] Test loss:\", test_loss_pre, \" | Test macro-F1:\", f1_pre)\n",
    "print(classification_report(y_test, y_pred_pre, target_names=le.classes_))"
   ],
   "id": "4d5a2cc8b0dba6f0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LSTM + Pretrained Emb] Test loss: 2.6293485164642334  | Test macro-F1: 0.24300538830030236\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alarm_query       0.48      0.63      0.55        19\n",
      "            alarm_remove       0.62      0.73      0.67        11\n",
      "               alarm_set       0.56      0.79      0.65        19\n",
      "       audio_volume_down       0.50      0.12      0.20         8\n",
      "       audio_volume_mute       0.20      0.13      0.16        15\n",
      "         audio_volume_up       0.33      0.15      0.21        13\n",
      "          calendar_query       0.11      0.05      0.07        19\n",
      "         calendar_remove       0.24      0.32      0.27        19\n",
      "            calendar_set       0.15      0.16      0.15        19\n",
      "          cooking_recipe       0.14      0.16      0.15        19\n",
      "        datetime_convert       0.25      0.12      0.17         8\n",
      "          datetime_query       0.35      0.63      0.45        19\n",
      "        email_addcontact       0.00      0.00      0.00         8\n",
      "             email_query       0.31      0.26      0.29        19\n",
      "      email_querycontact       0.00      0.00      0.00        19\n",
      "         email_sendemail       0.35      0.32      0.33        19\n",
      "          general_affirm       0.37      0.68      0.48        19\n",
      "     general_commandstop       0.58      0.37      0.45        19\n",
      "         general_confirm       0.47      1.00      0.64        19\n",
      "        general_dontcare       0.38      0.63      0.47        19\n",
      "         general_explain       0.67      0.42      0.52        19\n",
      "            general_joke       0.00      0.00      0.00        12\n",
      "          general_negate       0.62      0.53      0.57        19\n",
      "          general_praise       0.44      0.37      0.40        19\n",
      "          general_quirky       0.00      0.00      0.00        19\n",
      "          general_repeat       0.64      0.37      0.47        19\n",
      "            iot_cleaning       0.55      0.38      0.44        16\n",
      "              iot_coffee       0.35      0.47      0.40        19\n",
      "     iot_hue_lightchange       0.34      0.53      0.42        19\n",
      "        iot_hue_lightdim       0.33      0.17      0.22        12\n",
      "        iot_hue_lightoff       0.42      0.84      0.56        19\n",
      "         iot_hue_lighton       0.00      0.00      0.00         3\n",
      "         iot_hue_lightup       0.29      0.29      0.29        14\n",
      "            iot_wemo_off       0.33      0.11      0.17         9\n",
      "             iot_wemo_on       0.00      0.00      0.00         7\n",
      "       lists_createoradd       0.31      0.68      0.43        19\n",
      "             lists_query       0.27      0.16      0.20        19\n",
      "            lists_remove       0.32      0.37      0.34        19\n",
      "          music_likeness       0.10      0.06      0.07        18\n",
      "             music_query       0.25      0.05      0.09        19\n",
      "          music_settings       0.00      0.00      0.00         7\n",
      "              news_query       0.19      0.32      0.24        19\n",
      "          play_audiobook       0.00      0.00      0.00        19\n",
      "               play_game       0.30      0.53      0.38        19\n",
      "              play_music       0.40      0.21      0.28        19\n",
      "           play_podcasts       0.12      0.26      0.17        19\n",
      "              play_radio       0.00      0.00      0.00        19\n",
      "             qa_currency       0.22      0.32      0.26        19\n",
      "           qa_definition       0.22      0.53      0.31        19\n",
      "              qa_factoid       0.14      0.47      0.21        19\n",
      "                qa_maths       0.20      0.14      0.17        14\n",
      "                qa_stock       0.07      0.05      0.06        19\n",
      "   recommendation_events       0.18      0.11      0.13        19\n",
      "recommendation_locations       0.00      0.00      0.00        19\n",
      "   recommendation_movies       0.00      0.00      0.00        10\n",
      "             social_post       0.18      0.16      0.17        19\n",
      "            social_query       0.00      0.00      0.00        18\n",
      "          takeaway_order       0.17      0.05      0.08        19\n",
      "          takeaway_query       0.25      0.16      0.19        19\n",
      "         transport_query       0.03      0.05      0.03        19\n",
      "          transport_taxi       0.30      0.17      0.21        18\n",
      "        transport_ticket       0.52      0.63      0.57        19\n",
      "       transport_traffic       0.13      0.16      0.14        19\n",
      "           weather_query       0.00      0.00      0.00        19\n",
      "\n",
      "                accuracy                           0.29      1076\n",
      "               macro avg       0.25      0.27      0.24      1076\n",
      "            weighted avg       0.26      0.29      0.26      1076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:50:52.661748Z",
     "start_time": "2025-11-11T12:50:26.742625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Nhiệm vụ 4: Embedding học từ đầu + LSTM (trainable)\n",
    "# ==========================================================\n",
    "lstm_scratch = KSequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=100,\n",
    "        input_length=max_len\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    KDense(num_classes, activation='softmax')\n",
    "])\n",
    "lstm_scratch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es3 = EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "hist_scratch = lstm_scratch.fit(\n",
    "    X_train_pad, y_train_oh,\n",
    "    validation_data=(X_val_pad, y_val_oh),\n",
    "    epochs=20, batch_size=64, callbacks=[es3], verbose=0\n",
    ")\n",
    "\n",
    "test_loss_scratch, test_acc_scratch = lstm_scratch.evaluate(X_test_pad, y_test_oh, verbose=0)\n",
    "y_pred_scratch = lstm_scratch.predict(X_test_pad, verbose=0).argmax(axis=1)\n",
    "f1_scratch = f1_score(y_test, y_pred_scratch, average=\"macro\")\n",
    "print(\"\\n[LSTM + Scratch Emb] Test loss:\", test_loss_scratch, \" | Test macro-F1:\", f1_scratch)\n",
    "print(classification_report(y_test, y_pred_scratch, target_names=le.classes_))"
   ],
   "id": "4beebd8ab5bf33c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LSTM + Scratch Emb] Test loss: 0.7727429866790771  | Test macro-F1: 0.7920257455744357\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alarm_query       0.94      0.89      0.92        19\n",
      "            alarm_remove       0.92      1.00      0.96        11\n",
      "               alarm_set       0.81      0.89      0.85        19\n",
      "       audio_volume_down       0.88      0.88      0.88         8\n",
      "       audio_volume_mute       0.72      0.87      0.79        15\n",
      "         audio_volume_up       0.86      0.92      0.89        13\n",
      "          calendar_query       0.45      0.47      0.46        19\n",
      "         calendar_remove       0.95      1.00      0.97        19\n",
      "            calendar_set       0.86      0.63      0.73        19\n",
      "          cooking_recipe       0.57      0.63      0.60        19\n",
      "        datetime_convert       0.67      0.75      0.71         8\n",
      "          datetime_query       0.89      0.84      0.86        19\n",
      "        email_addcontact       0.86      0.75      0.80         8\n",
      "             email_query       0.84      0.84      0.84        19\n",
      "      email_querycontact       0.76      0.68      0.72        19\n",
      "         email_sendemail       0.84      0.84      0.84        19\n",
      "          general_affirm       1.00      1.00      1.00        19\n",
      "     general_commandstop       0.76      1.00      0.86        19\n",
      "         general_confirm       0.90      1.00      0.95        19\n",
      "        general_dontcare       0.85      0.89      0.87        19\n",
      "         general_explain       0.89      0.89      0.89        19\n",
      "            general_joke       0.85      0.92      0.88        12\n",
      "          general_negate       0.79      1.00      0.88        19\n",
      "          general_praise       0.86      1.00      0.93        19\n",
      "          general_quirky       0.32      0.32      0.32        19\n",
      "          general_repeat       0.95      1.00      0.97        19\n",
      "            iot_cleaning       1.00      0.94      0.97        16\n",
      "              iot_coffee       1.00      0.95      0.97        19\n",
      "     iot_hue_lightchange       0.78      0.74      0.76        19\n",
      "        iot_hue_lightdim       0.83      0.83      0.83        12\n",
      "        iot_hue_lightoff       1.00      0.89      0.94        19\n",
      "         iot_hue_lighton       0.00      0.00      0.00         3\n",
      "         iot_hue_lightup       0.71      0.71      0.71        14\n",
      "            iot_wemo_off       0.75      0.67      0.71         9\n",
      "             iot_wemo_on       0.67      0.86      0.75         7\n",
      "       lists_createoradd       0.68      0.89      0.77        19\n",
      "             lists_query       0.67      0.74      0.70        19\n",
      "            lists_remove       0.88      0.79      0.83        19\n",
      "          music_likeness       0.86      0.67      0.75        18\n",
      "             music_query       0.85      0.58      0.69        19\n",
      "          music_settings       0.67      0.86      0.75         7\n",
      "              news_query       0.86      0.63      0.73        19\n",
      "          play_audiobook       0.73      0.58      0.65        19\n",
      "               play_game       1.00      0.63      0.77        19\n",
      "              play_music       0.52      0.68      0.59        19\n",
      "           play_podcasts       1.00      0.74      0.85        19\n",
      "              play_radio       0.88      0.74      0.80        19\n",
      "             qa_currency       1.00      0.89      0.94        19\n",
      "           qa_definition       0.70      1.00      0.83        19\n",
      "              qa_factoid       0.41      0.37      0.39        19\n",
      "                qa_maths       0.71      0.86      0.77        14\n",
      "                qa_stock       0.90      0.95      0.92        19\n",
      "   recommendation_events       0.79      0.79      0.79        19\n",
      "recommendation_locations       0.80      0.63      0.71        19\n",
      "   recommendation_movies       0.90      0.90      0.90        10\n",
      "             social_post       1.00      0.89      0.94        19\n",
      "            social_query       0.61      0.78      0.68        18\n",
      "          takeaway_order       0.94      0.84      0.89        19\n",
      "          takeaway_query       0.94      0.89      0.92        19\n",
      "         transport_query       0.71      0.79      0.75        19\n",
      "          transport_taxi       1.00      1.00      1.00        18\n",
      "        transport_ticket       0.93      0.74      0.82        19\n",
      "       transport_traffic       0.94      0.89      0.92        19\n",
      "           weather_query       0.54      0.68      0.60        19\n",
      "\n",
      "                accuracy                           0.80      1076\n",
      "               macro avg       0.80      0.80      0.79      1076\n",
      "            weighted avg       0.81      0.80      0.80      1076\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/tbao04/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:53:27.983156Z",
     "start_time": "2025-11-11T12:53:27.479702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================================\n",
    "# Nhiệm vụ 5: Bảng so sánh định lượng + Phân tích định tính\n",
    "# ==========================================================\n",
    "results = pd.DataFrame({\n",
    "    \"Pipeline\": [\n",
    "        \"TF-IDF + Logistic Regression\",\n",
    "        \"Word2Vec (Avg) + Dense\",\n",
    "        \"Embedding (Pre-trained) + LSTM\",\n",
    "        \"Embedding (Scratch) + LSTM\"\n",
    "    ],\n",
    "    \"F1-score (Macro)\": [\n",
    "        f1_lr,\n",
    "        f1_dense,\n",
    "        f1_pre,\n",
    "        f1_scratch\n",
    "    ],\n",
    "    \"Test Loss\": [\n",
    "        np.nan,\n",
    "        test_loss_dense,\n",
    "        test_loss_pre,\n",
    "        test_loss_scratch\n",
    "    ]\n",
    "})\n",
    "print(\"\\n=== Tổng hợp kết quả (Test) ===\")\n",
    "print(results)\n",
    "\n",
    "# --------- Phân tích định tính ----------\n",
    "hard_sentences = [\n",
    "    (\"can you remind me to not call my mom\", None),         # kỳ vọng: reminder_create\n",
    "    (\"is it going to be sunny or rainy tomorrow\", None),    # kỳ vọng: weather_query\n",
    "    (\"find a flight from new york to london but not through paris\", None)  # kỳ vọng: flight_search\n",
    "]\n",
    "\n",
    "def predict_all_models(raw_text):\n",
    "    # 1) TF-IDF + LR\n",
    "    pred_lr = le.classes_[tfidf_lr_pipeline.predict([raw_text])[0]]\n",
    "\n",
    "    # 2) W2V Avg + Dense\n",
    "    x_avg = sentence_to_avg_vector(raw_text, w2v_model, w2v_model.vector_size).reshape(1, -1)\n",
    "    pred_dense = le.classes_[dense_avg.predict(x_avg, verbose=0).argmax(axis=1)[0]]\n",
    "\n",
    "    # 3) LSTM pretrained\n",
    "    x_pad = to_padded([raw_text], tokenizer, max_len)\n",
    "    pred_pre = le.classes_[lstm_pre.predict(x_pad, verbose=0).argmax(axis=1)[0]]\n",
    "\n",
    "    # 4) LSTM scratch\n",
    "    pred_scr = le.classes_[lstm_scratch.predict(x_pad, verbose=0).argmax(axis=1)[0]]\n",
    "\n",
    "    return pred_lr, pred_dense, pred_pre, pred_scr\n",
    "\n",
    "print(\"\\n=== Phân tích định tính trên các câu 'khó' ===\")\n",
    "for sent, gold in hard_sentences:\n",
    "    p_lr, p_dense, p_pre, p_scr = predict_all_models(sent)\n",
    "    print(f\"\\nCâu: {sent}\")\n",
    "    print(f\" - TF-IDF+LR:              {p_lr}\")\n",
    "    print(f\" - W2V(Avg)+Dense:         {p_dense}\")\n",
    "    print(f\" - LSTM + Pretrained Emb:  {p_pre}\")\n",
    "    print(f\" - LSTM + Scratch Emb:     {p_scr}\")\n",
    "    if gold is not None:\n",
    "        print(f\" -> Nhãn thật: {gold}\")\n",
    "\n",
    "# Gợi ý diễn giải (để bạn ghi trong báo cáo):\n",
    "explanation = \"\"\"\n",
    "Phân tích:\n",
    "- Các câu có phủ định ('not call', 'not through paris') và cấu trúc phụ thuộc dài thường được LSTM xử lý tốt hơn\n",
    "  vì nó mô hình hóa chuỗi theo thời gian, giữ ngữ cảnh và quan hệ giữa các token.\n",
    "- TF-IDF + LR bỏ qua thứ tự từ; Word2Vec(trung bình) mất cấu trúc chuỗi => có thể nhầm với các ý định gần nghĩa.\n",
    "- LSTM + pretrained embedding thường hội tụ nhanh và tổng quát tốt hơn khi dữ liệu train không quá lớn.\n",
    "- LSTM học từ đầu có thể theo kịp hoặc vượt nếu dữ liệu phong phú, nhưng dễ overfit nếu dữ liệu ít.\n",
    "\"\"\"\n",
    "print(explanation)\n"
   ],
   "id": "5e444c518d993e9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tổng hợp kết quả (Test) ===\n",
      "                         Pipeline  F1-score (Macro)  Test Loss\n",
      "0    TF-IDF + Logistic Regression          0.829401        NaN\n",
      "1          Word2Vec (Avg) + Dense          0.148429   3.091791\n",
      "2  Embedding (Pre-trained) + LSTM          0.243005   2.629349\n",
      "3      Embedding (Scratch) + LSTM          0.792026   0.772743\n",
      "\n",
      "=== Phân tích định tính trên các câu 'khó' ===\n",
      "\n",
      "Câu: can you remind me to not call my mom\n",
      " - TF-IDF+LR:              calendar_set\n",
      " - W2V(Avg)+Dense:         general_explain\n",
      " - LSTM + Pretrained Emb:  email_query\n",
      " - LSTM + Scratch Emb:     calendar_set\n",
      "\n",
      "Câu: is it going to be sunny or rainy tomorrow\n",
      " - TF-IDF+LR:              weather_query\n",
      " - W2V(Avg)+Dense:         email_query\n",
      " - LSTM + Pretrained Emb:  transport_query\n",
      " - LSTM + Scratch Emb:     weather_query\n",
      "\n",
      "Câu: find a flight from new york to london but not through paris\n",
      " - TF-IDF+LR:              transport_query\n",
      " - W2V(Avg)+Dense:         general_dontcare\n",
      " - LSTM + Pretrained Emb:  transport_ticket\n",
      " - LSTM + Scratch Emb:     transport_query\n",
      "\n",
      "Phân tích:\n",
      "- Các câu có phủ định ('not call', 'not through paris') và cấu trúc phụ thuộc dài thường được LSTM xử lý tốt hơn\n",
      "  vì nó mô hình hóa chuỗi theo thời gian, giữ ngữ cảnh và quan hệ giữa các token.\n",
      "- TF-IDF + LR bỏ qua thứ tự từ; Word2Vec(trung bình) mất cấu trúc chuỗi => có thể nhầm với các ý định gần nghĩa.\n",
      "- LSTM + pretrained embedding thường hội tụ nhanh và tổng quát tốt hơn khi dữ liệu train không quá lớn.\n",
      "- LSTM học từ đầu có thể theo kịp hoặc vượt nếu dữ liệu phong phú, nhưng dễ overfit nếu dữ liệu ít.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
